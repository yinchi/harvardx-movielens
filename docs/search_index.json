[["index.html", "HarvardX PH125.9x: Movielens project Preface 0.1 R setup", " HarvardX PH125.9x: Movielens project Yin-Chi Chan 2022-04-13 Preface This book is available in both HTML gitbook and PDF form. The source code in the PDF version of this report is typeset in Cascadia Code, with code ligatures enabled. A similar font, Fira Code, is used in the HTML version. 0.1 R setup # R 4.1 key features: new pipe operator, \\(x) as shortcut for function(x) # R 4.0 key features: stringsAsFactors = FALSE by default, raw character strings r&quot;()&quot; if (packageVersion(&#39;base&#39;) &lt; &#39;4.1.0&#39;) { stop(&#39;This code requires R &gt;= 4.1.0!&#39;) } if(!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) library(pacman) # Ensure packages are installed but do not load them p_install(Rcpp, force = F) p_install(RcppArmadillo, force = F) p_install(RcppProgress, force = F) p_install(recommenderlab, force = F) p_install(rrecsys, force = F) p_install(mgcv, force = F) # provides mgcv::gam and mgcv::predict.gam p_install(raster, force = F) # provides raster::clamp # Load these packages p_load(conflicted, magrittr, knitr, kableExtra, data.table, latex2exp, patchwork, tidyverse, caret, lubridate) # For functions with identical names in different packages, ensure the # right one is chosen conflict_prefer(&#39;RMSE&#39;, &#39;caret&#39;) conflict_prefer(&quot;first&quot;, &quot;dplyr&quot;) "],["introduction.html", "Chapter 1 Introduction 1.1 Data description 1.2 Project Objective", " Chapter 1 Introduction This report partially fulfills the requirements for the HarvardX course PH125.9x: Data Science: Capstone. The objective of this process is to build a movie recommendation system using the MovieLens dataset. The 10M version (GroupLens 2009) of this dataset was used for this project. Using the code provided by the course, the 10 million records of the MovieLens 10M dataset are split into the edx partition, for building the movie recommendation system, and the validation partition, for evaluating the proposed system. The validation dataset contains roughly 10 percent of the records in the MovieLens 10M dataset. The code for generating these two datasets is provided below: ########################################################## # Create edx set, validation set (final hold-out test set) ########################################################## # NOTE: this code was modified from the course-provided version for speed. # MovieLens 10M dataset: # https://grouplens.org/datasets/movielens/10m/ # http://files.grouplens.org/datasets/movielens/ml-10m.zip # STEP 1: download and unzip &#39;ml-10m.zip&#39; as necessary if(!dir.exists(&quot;ml-10M100K&quot;)) dir.create(&quot;ml-10M100K&quot;) dl &lt;- &quot;ml-10M100K/ratings.zip&quot; if(!file.exists(dl)) download.file(&quot;https://files.grouplens.org/datasets/movielens/ml-10m.zip&quot;, dl) ratings_file &lt;- &quot;ml-10M100K/ratings.dat&quot; if(!file.exists(ratings_file)) unzip(dl, ratings_file) movies_file &lt;- &quot;ml-10M100K/movies.dat&quot; if(!file.exists(movies_file)) unzip(dl, movies_file) # STEP 2a: Load the ratings file. This file is delimited using double colons. ratings &lt;- str_split(read_lines(ratings_file), fixed(&quot;::&quot;), simplify = T) |&gt; as.data.frame() |&gt; set_colnames(c(&quot;userId&quot;, &quot;movieId&quot;, &quot;rating&quot;, &quot;timestamp&quot;)) |&gt; mutate(userId = as.integer(userId), movieId = as.integer(movieId), rating = as.numeric(rating), timestamp = as_datetime(as.integer(timestamp))) # STEP 2b: Load the movies file. Again, this file is delimited using double colons. movies &lt;- str_split(read_lines(movies_file), fixed(&quot;::&quot;), simplify = T) |&gt; as.data.frame() |&gt; set_colnames(c(&quot;movieId&quot;, &quot;title&quot;, &quot;genres&quot;)) |&gt; mutate(movieId = as.integer(movieId)) # STEP 3: Join the `ratings` and `movies` data tables and save to `movielens`. movielens &lt;- left_join(ratings, movies, by = &quot;movieId&quot;) # STEP 4: Split the `movielens` dataset into the `edx` and `validation` sets. # Validation set will be 10% of MovieLens data set.seed(1, sample.kind=&quot;Rounding&quot;) test_index &lt;- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE) edx &lt;- movielens[-test_index,] temp &lt;- movielens[test_index,] # Make sure userId and movieId in validation set are also in edx set validation &lt;- temp |&gt; semi_join(edx, by = &quot;movieId&quot;) |&gt; semi_join(edx, by = &quot;userId&quot;) # Add rows removed from validation set back into edx set removed &lt;- anti_join(temp, validation) edx &lt;- rbind(edx, removed) # STEP 5; convert timestamps to datetime edx &lt;- edx |&gt; mutate(timestamp = as_datetime(timestamp)) |&gt; as.data.table() validation &lt;- validation |&gt; mutate(timestamp = as_datetime(timestamp)) |&gt; as.data.table() rm(dl, ratings, movies, test_index, temp, movielens, removed) 1.1 Data description The data consists of ten million movie ratings, each expressed using six variables. The number of ratings in the edx and validation partitions are nrow(edx) and nrow(validation), respectively, i.e., 9000055 and 999999. The six variables are: colnames(edx) ## [1] &quot;userId&quot; &quot;movieId&quot; &quot;rating&quot; &quot;timestamp&quot; &quot;title&quot; &quot;genres&quot; and are defined as follows: userId: an integer from 1 to 71567 denoting the user who made the rating. movieId: an integer from 1 to 65133 denoting which movie was rated. rating: a multiple of 0.5, from 0.5 to 5.0. timestamp: a POSIXct object representing the time at which the rating was made. title: the name of the movie rated, suffixed which the year of release in parentheses. genres: a list of genres for the rated movie, delimited by the pipe (|) character. Note that only integer ratings were supported before February 2003; the earliest half-star rating is: temp &lt;- edx[edx$rating %% 1 == 0.5] temp[which.min(temp$timestamp)] |&gt; kable(align=&#39;rrrrll&#39;, booktabs = T) |&gt; row_spec(0, bold = T) userId movieId rating timestamp title genres 53996 4018 3.5 2003-02-12 17:31:34 What Women Want (2000) Comedy|Romance The density of the rating matrix is: nrow(edx) / max(edx$userId) / max(edx$movieId) ## [1] 0.001930773 The number of ratings per movie and per user in edx is plotted below. # Count the number of ratings for each movie and rank the movies by ratings received ratings_per_movie &lt;- edx |&gt; group_by(movieId) |&gt; summarise(title = first(title), genres = first(genres), n_ratings = n()) |&gt; mutate(rank = frank(-n_ratings)) # Count the number of ratings for each user and rank the users by ratings given ratings_per_user &lt;- edx |&gt; group_by(userId) |&gt; summarise(n_ratings = n()) |&gt; mutate(rank = frank(-n_ratings)) # Plot the number of ratings for each movie and user, sorted by rank plot1 &lt;- ratings_per_movie |&gt; ggplot(aes(rank,n_ratings)) + geom_line() + scale_x_log10() + scale_y_log10() + xlab(&#39;Rank&#39;) + ylab(&#39;Number of ratings&#39;) + labs(title = &#39;Ratings per movie&#39;) plot2 &lt;- ratings_per_user |&gt; ggplot(aes(rank,n_ratings)) + geom_line() + scale_x_log10() + scale_y_log10() + xlab(&#39;Rank&#39;) + ylab(&#39;Number of ratings&#39;) + labs(title = &#39;Ratings per user&#39;) rm(ratings_per_movie, ratings_per_user) par(cex = 0.7) plot1 + plot2 1.1.1 Movie genres The list of possible genres, the number of movies in each genre, and the mean number of ratings per movie in each genre is given as follows: # Get the list of possible genres genres &lt;- edx$genres |&gt; unique() |&gt; str_split(&#39;\\\\|&#39;) |&gt; flatten_chr() |&gt; unique() |&gt; sort() |&gt; tail(-1) # remove &quot;(no genres listed)&quot; # Construct a data.table with one entry per movie temp &lt;- edx |&gt; group_by(movieId) |&gt; summarise(title = first(title), genres = first(genres)) # Find the number of movies and ratings for each genre genre_summary &lt;- data.table( Genre = genres, Movies = sapply(genres, function(g) sum(temp$genres %flike% g)), Ratings = sapply(genres, function(g) sum(edx$genres %flike% g)), &quot;Mean Rating&quot; = sapply(genres, function(g) { edx[edx$genres %flike% g,&#39;rating&#39;]$rating |&gt; mean() }) ) |&gt; mutate(&quot;Ratings per movie&quot; = Ratings / Movies) rm(temp) genre_summary |&gt; arrange(desc(`Mean Rating`)) |&gt; kable(align=&#39;lrrrr&#39;, digits = c(0,0,0,2,1), booktabs = T, linesep = &quot;&quot;) |&gt; row_spec(0, bold = T) Genre Movies Ratings Mean Rating Ratings per movie Film-Noir 148 118541 4.01 801.0 Documentary 481 93066 3.78 193.5 War 510 511147 3.78 1002.2 IMAX 29 8181 3.77 282.1 Mystery 509 568332 3.68 1116.6 Drama 5336 3910127 3.67 732.8 Crime 1117 1327715 3.67 1188.6 Animation 286 467168 3.60 1633.5 Musical 436 433080 3.56 993.3 Western 275 189394 3.56 688.7 Romance 1685 1712100 3.55 1016.1 Thriller 1705 2325899 3.51 1364.2 Fantasy 543 925637 3.50 1704.7 Adventure 1025 1908892 3.49 1862.3 Comedy 3703 3540930 3.44 956.2 Action 1473 2560545 3.42 1738.3 Children 528 737994 3.42 1397.7 Sci-Fi 754 1341183 3.40 1778.8 Horror 1013 691485 3.27 682.6 The number of genres for each movie is plotted as a histogram below: genre_counts &lt;- table(str_count(edx$genres, &#39;\\\\|&#39;) + 1 - str_count(edx$genres, &#39;no genres&#39;)) par(cex = 0.7) barplot(genre_counts, xlab = &#39;Number of genres&#39;, ylab = &#39;Count&#39;, main = &#39;Genres per movie&#39;) Therefore, it is likely better to analyze genre combinations rather than individual genres. The following code confirms that over half of all movies have either two or three genres: sum(genre_counts[c(&#39;2&#39;,&#39;3&#39;)])/sum(genre_counts) ## [1] 0.595434 1.2 Project Objective The objective of this project is to estimate movie ratings given the values of the other five variables. The goodness of the proposed recommender system is evaluated using the root mean squared error (RMSE): \\[ \\text{RMSE} = \\sqrt{\\frac{1}{\\left|\\mathcal{T}\\right|}\\sum_{(u,i)\\in\\mathcal{T}} \\left(y_{u,i} - \\hat{y}_{u,i}\\right)^2} \\] where \\(y\\) denotes the true values of movie ratings in the test set \\(\\mathcal{T}\\), \\(\\hat{y}\\) denotes the estimated values, and \\(N\\) denotes the number of observations in the test set. The library function caret::RSME is used in this report for RSME evaluation. Note that minimizing the RMSE is equivalent to minimizing the sum of the square errors, i.e., \\[ \\text{SE} = \\sum_{(u,i)\\in\\mathcal{T}} \\left(y_{u,i} - \\hat{y}_{u,i}\\right)^2. \\] In matrix form, this can be thought of as the square of the \\(L_{2,2}\\) or Frobenius norm of the prediction errors, i.e., \\[ \\text{SE} = \\left\\Vert Y - \\hat{Y} \\right\\Vert_{2,2}^2, \\] where \\(Y - \\hat{Y}\\) is defined as zero for user-movie pairs not in the test set. References "],["sec-linear-models.html", "Chapter 2 Linear regression models 2.1 Overview and notation 2.2 Using the mean rating only 2.3 Modeling movie effects 2.4 Modeling movie and user effects 2.5 Adding genre effects 2.6 Adding a time effect 2.7 Adding \\(L_2\\) regularization 2.8 Section summary", " Chapter 2 Linear regression models We start by splitting edx into a training and test set: # Test set will be 10% of edx data set.seed(1, sample.kind=&quot;Rounding&quot;) test_index &lt;- createDataPartition(y = edx$rating, times = 1, p = 0.1, list = FALSE) edx_train &lt;- edx[-test_index,] temp &lt;- edx[test_index,] # Make sure userId and movieId in edx_test set are also in edx_train set edx_test &lt;- temp |&gt; semi_join(edx_train, by = &quot;movieId&quot;) |&gt; semi_join(edx_train, by = &quot;userId&quot;) |&gt; as.data.table() # Add rows removed from edx_test set back into edx_train set removed2 &lt;- anti_join(temp, edx_test) edx_train &lt;- rbind(edx_train, removed2) |&gt; as.data.table() rm(removed2, temp, test_index) 2.1 Overview and notation Let \\(Y\\) be a \\(N_\\mathrm{U}\\times N_\\mathrm{M}\\) matrix of movie ratings, such that \\(Y_{u,i}\\) is the rating user \\(u\\) has given or would give movie \\(i\\). Additionally, define \\(X_j\\) such that \\(X_{u,i}\\) denotes the \\(j\\)th attribute of user-movie pair \\((u,i)\\). Such attributes include \\(u\\) and \\(i\\) themselves, the genres of movie \\(i\\), and the timestamp at which the rating was made. Finally, only the indices \\((u,i)\\) in the training set, denoted \\(\\mathcal{T}\\), are observable. The goal is to estimate \\(Y\\) given the observable elements of \\(Y\\) (the actual ratings). Given a user-movie pair \\((u,i)\\), we model \\(Y_r\\) using a multiple linear regression model: \\[ y_{u,i} \\sim \\mu + \\left(\\sum_j \\beta_{j;u,i} \\right) +\\varepsilon_{u,i}, \\] where \\(\\mu\\) represents the true rating for all movies, \\(\\beta_{j;u,i}\\) is the \\(j\\)th bias term for pair \\((u,i)\\), and \\(\\varepsilon_{u,i}\\) is random error, all independently sampled from the same zero-mean distribution. We further define \\(b_j\\) such that \\[ \\left(X_{j;u,i} = n\\right) \\implies \\left(\\beta_{j;u,i} = b_{j;n}\\right). \\] We can write the above in matrix form: \\[ Y \\sim \\mu + \\left( \\sum_j \\beta_j \\right) + \\varepsilon. \\] The objective is to minimize the sum of the squared errors \\[ \\text{SE} = \\sum_{(u,i)\\in\\mathcal{T}} \\left[Y_{u,i} - \\mu - \\sum_j \\beta_{j;u,i} \\right]^2 \\] where \\(\\mathcal{T}\\) represents the test set of observed movie ratings. The estimated value of \\(Y_{u,v}\\) for \\((u,v) \\notin \\mathcal{T}\\) is \\[ \\hat{Y}_{u,v} = \\mu + \\sum_j \\beta_{j;u,v}. \\] 2.2 Using the mean rating only Our first model is of the form \\[ Y_{u,i} \\sim \\mu + \\varepsilon_{u,i}. \\] The best estimate \\(\\hat{\\mu}\\) of \\(\\mu\\) is the mean of all ratings in edx_train, or: mu &lt;- mean(edx_test$rating) mu ## [1] 3.512551 This model gives the following RMSE values when applied to edx_test: # When multiple effects (movie, user, genre) are added in our model, some predictions # may fall out of the valid range. This function fixes these predictions to the range # [0.5, 5]. clamp &lt;- function(x) raster::clamp(as.numeric(x), 0.5, 5) # Compute RMSE and add to a tibble. RMSEs &lt;- tibble(Method = c(&quot;Mean only&quot;), RMSE = RMSE(mu, edx_test$rating), &quot;RMSE (clamped estimates)&quot; = RMSE(mu, edx_test$rating)) RMSEs[[nrow(RMSEs),&#39;RMSE&#39;]] ## [1] 1.060054 2.3 Modeling movie effects We add a term to our model for movie effects: \\[ Y_{u,i} \\sim \\mu + b_{1;i}i + \\varepsilon_{u,i}, \\] The least-squares estimate \\(\\hat{b}_{1;i}\\) of \\(b_{1;i}\\) is the training-set mean of \\(Y_{u,i} - \\hat{\\mu}\\) for each movie \\(i\\). The following code computes \\(\\hat{b}_{1;i}\\) for each \\(i\\) and plots these as a histogram: # Least-squares estimate of movie effect is the mean of (rating - mu) for all # ratings of that movie. movie_biases &lt;- edx_train |&gt; group_by(movieId) |&gt; summarize(b_i = mean(rating - mu)) # Plot a histogram of the movie effects par(cex = 0.7) hist(movie_biases$b_i, 30, xlab = TeX(r&#39;[$\\hat{b}_{1,i}$]&#39;), main = TeX(r&#39;[Histogram of $\\hat{b}_{1,i}$]&#39;)) The new model gives the following RMSE values when applied to edx_test: # Obtain predictions for the edx_test set predicted_ratings &lt;- edx_test |&gt; left_join(movie_biases, by=&#39;movieId&#39;) |&gt; mutate(pred = mu + b_i) |&gt; pull(pred) # Compute RMSE and add to data.table RMSEs &lt;- RMSEs |&gt; add_row(Method = &quot;Movie effects&quot;, RMSE = RMSE(predicted_ratings, edx_test$rating), &quot;RMSE (clamped estimates)&quot; = RMSE(clamp(predicted_ratings), edx_test$rating)) RMSEs[nrow(RMSEs),] |&gt; kable(align=&#39;lrr&#39;, booktabs = T) |&gt; row_spec(0, bold = T) Method RMSE RMSE (clamped estimates) Movie effects 0.9429615 0.9429615 2.3.1 Clamping the predictions In the above table, clamping means setting any predictions less than 0.5 to 0.5, and any predictions greater than 5.0 to 5.0, thus enforcing the limits of possible ratings. This slightly reduces the RMSE when multiple biases are added to the model, as we demonstrate below. 2.4 Modeling movie and user effects We add a term \\(b_u\\) to our model for user effects: \\[ Y_{u,i} \\sim \\mu + b_{1;i}i + b_{2;u}u + \\varepsilon_{u,i}. \\] We approximate \\(b_{2,u}\\) for each user \\(u\\) as the mean of \\(\\hat{b}_u = Y_{u,i} - \\hat{\\mu} - \\hat{b}_{1;i}\\). The following code computes \\(\\hat{b}_{2;u}\\) for each \\(u\\) and plots these as a histogram: # Estimate user effects user_biases &lt;- edx_train |&gt; left_join(movie_biases, by=&#39;movieId&#39;) |&gt; group_by(userId) |&gt; summarize(b_u = mean(rating - mu - b_i)) # Plot a histogram of the user effects par(cex = 0.7) hist(user_biases$b_u, 30, xlab = TeX(r&#39;[$\\hat{b}_{2,u}$]&#39;), main = TeX(r&#39;[Histogram of $\\hat{b}_{2,u}$]&#39;)) The new model gives the following RMSE values when applied to the edx_test set: # Obtain predictions for the edx_test set predicted_ratings &lt;- edx_test |&gt; left_join(movie_biases, by=&#39;movieId&#39;) |&gt; left_join(user_biases, by=&#39;userId&#39;) |&gt; mutate(pred = mu + b_i + b_u) |&gt; pull(pred) # Compute RMSE and add to data.table RMSEs &lt;- RMSEs |&gt; add_row(Method = &quot;Movie + user effects&quot;, RMSE = RMSE(predicted_ratings, edx_test$rating), &quot;RMSE (clamped estimates)&quot; = RMSE(clamp(predicted_ratings), edx_test$rating)) RMSEs[nrow(RMSEs),] |&gt; kable(align=&#39;lrr&#39;, booktabs = T) |&gt; row_spec(0, bold = T) Method RMSE RMSE (clamped estimates) Movie + user effects 0.8646843 0.8644818 2.5 Adding genre effects We add another bias term \\(b_g\\) to our model for genre effects: \\[ Y_{u,i} \\sim \\mu + b_{1;i} + b_{2;u} + b_{3;g(i)} + \\varepsilon_{u,i}, \\] where \\(g(i)\\) is the combination of genres for movie \\(i\\). We approximate \\(b_{3;g}\\) for each genre combination \\(g\\) as the mean of \\(\\hat{b}_u = Y_{u;i} - \\hat{\\mu} - \\hat{b}_{1;i} - \\hat{b}_{2;u}\\), averaged over all ratings in the training set where \\(g(i) = g\\). The following code computes \\(\\hat{b}_{3,g}\\) for each \\(g\\) and plots these as a histogram: # Estimate genre effects genre_biases &lt;- edx_train |&gt; left_join(movie_biases, by=&#39;movieId&#39;) |&gt; left_join(user_biases, by=&#39;userId&#39;) |&gt; group_by(genres) |&gt; summarize(b_g = mean(rating - mu - b_i - b_u)) # Plot a histogram of the genre effects par(cex = 0.7) hist(genre_biases$b_g, 30, xlab = TeX(r&#39;[$\\hat{b}_{3,g}$]&#39;), main = TeX(r&#39;[Histogram of $\\hat{b}_{3,g}$]&#39;)) The new model gives the following RMSE values when applied to the edx_test set: # Obtain predictions for the edx_test set predicted_ratings &lt;- edx_test |&gt; left_join(movie_biases, by=&#39;movieId&#39;) |&gt; left_join(user_biases, by=&#39;userId&#39;) |&gt; left_join(genre_biases, by=&#39;genres&#39;) |&gt; mutate(pred = mu + b_i + b_u + b_g) |&gt; pull(pred) # Compute RMSE and add to data.table RMSEs &lt;- RMSEs |&gt; add_row(Method = &quot;Movie + user + genre effects&quot;, RMSE = RMSE(predicted_ratings, edx_test$rating), &quot;RMSE (clamped estimates)&quot; = RMSE(clamp(predicted_ratings), edx_test$rating)) RMSEs[nrow(RMSEs),] |&gt; kable(align=&#39;lrr&#39;, booktabs = T) |&gt; row_spec(0, bold = T) Method RMSE RMSE (clamped estimates) Movie + user + genre effects 0.8643241 0.8641138 2.6 Adding a time effect Consider a new model with the form \\[ Y_{u,i} \\sim \\mu + b_{1;i} + b_{2;u} + b_{3;g(i)} + f(t_{u,i}) + \\varepsilon_{u,i}. \\] where \\(t_{u,i}\\) is a week index, such that the date of the oldest rating is defined as the start of Week 1. The new optimization problem minimizes \\[ \\text{SE} = \\sum_{(u,i)\\in\\mathcal{T}} \\left[y_{u,i} - \\mu - b_{1;i} - b_{2;u} - b_{3;g(i)} - f(t_{u,i})\\right]^2. \\] Note the addition of the \\(t\\) subscript compared to the original problem formulation defined in Section 2.1, with \\(\\mu_{t;u,i} = \\mu - f(t_{u,i})\\). The following code defines \\(f(t)\\) as the smoothed average rating on Week \\(t\\), minus \\(\\mu\\): # Add a week number to each rating in the edx_train and edx_test datasets edx_train &lt;- edx_train |&gt; mutate(weekNum = (timestamp - min(timestamp)) |&gt; as.numeric(unit = &quot;days&quot;) |&gt; {\\(x) floor(x/7) + 1}() ) edx_test &lt;- edx_test |&gt; mutate(weekNum = (timestamp - min(timestamp)) |&gt; as.numeric(unit = &quot;days&quot;) |&gt; {\\(x) floor(x/7) + 1}() ) # Fit a smooth curve to the ratings as a function of time fit &lt;- mgcv::gam(rating ~ s(weekNum, bs = &quot;cs&quot;), family = gaussian(), data = edx_train) # apply smoothing # Evaluate the fitted curve for each week number r &lt;- seq(1,max(edx_train$weekNum)) f_t &lt;- mgcv::predict.gam(fit, data.frame(weekNum = r)) - mu rm(fit) # Plot the fitted curve ggplot(data.frame(weekNum = r, f_t), aes(weekNum, f_t)) + geom_line() + xlab(TeX(r&#39;[$t_{u,i}$]&#39;)) + ylab(TeX(r&#39;[$f\\,(t_{u,i}\\,)$]&#39;)) We approximate \\(b_{t,g}\\) for each genre combination \\(g\\) as the mean of \\(\\hat{b}_u = Y_{u,i} - \\hat{\\mu} - \\hat{b}_{1;i} - \\hat{b}_{2;u} - b_{3;g(i)}\\). Fitting the \\(b_{j;t}\\)s \\(j=1,2,3\\), for the new model, we obtain RMSE values of: # Compute the biases movie_biases_t &lt;- edx_train |&gt; mutate(f_t = f_t[weekNum]) |&gt; group_by(movieId) |&gt; summarize(b_i = mean(rating - mu - f_t)) user_biases_t &lt;- edx_train |&gt; mutate(f_t = f_t[weekNum]) |&gt; left_join(movie_biases_t, by=&#39;movieId&#39;) |&gt; group_by(userId) |&gt; summarize(b_u = mean(rating - mu - b_i - f_t)) genre_biases_t &lt;- edx_train |&gt; mutate(f_t = f_t[weekNum]) |&gt; left_join(movie_biases_t, by=&#39;movieId&#39;) |&gt; left_join(user_biases_t, by=&#39;userId&#39;) |&gt; group_by(genres) |&gt; summarize(b_g = mean(rating - mu - b_i - b_u - f_t)) # Obtain predictions for the edx_test set predicted_ratings &lt;- edx_test |&gt; mutate(f_t = f_t[weekNum]) |&gt; left_join(movie_biases_t, by=&#39;movieId&#39;) |&gt; left_join(user_biases_t, by=&#39;userId&#39;) |&gt; left_join(genre_biases_t, by=&#39;genres&#39;) |&gt; mutate(pred = mu + b_i + b_u + b_g + f_t) |&gt; pull(pred) # Compute RMSE and add to data.table RMSEs &lt;- RMSEs |&gt; add_row(Method = &quot;Movie + user + genre + time effects&quot;, RMSE = RMSE(predicted_ratings, edx_test$rating), &quot;RMSE (clamped estimates)&quot; = RMSE(clamp(predicted_ratings), edx_test$rating)) RMSEs[nrow(RMSEs),] |&gt; kable(align=&#39;lrr&#39;, booktabs = T) |&gt; row_spec(0, bold = T) Method RMSE RMSE (clamped estimates) Movie + user + genre + time effects 0.8641266 0.8639174 2.7 Adding \\(L_2\\) regularization To improve our model further, we can add \\(L_2\\) regularization. Whereas the previous model fitting procedure minimizes \\[ \\text{SE} = \\sum_{(u,i)\\in\\mathcal{T}} \\left[y_{u,i} - \\mu - b_{1;i} - b_{2;u} - b_{3;g(i)} - f(t_{u,i})\\right]^2, \\] in this section we add a penalty term such that the new expression to minimize is as follows: \\[ \\text{SE} + \\lambda\\sum_j\\left\\Vert b_j\\right\\Vert_2^2. \\] Fitting the regularized model to the training set for different \\(\\lambda\\), and using the test set for RMSE calculation, we obtain the following plot of RMSE against \\(\\lambda\\). # List of regularization parameter values to try. # Since I know the approximate optimal value, I added more points # in this range. lambdas &lt;- c(0,1,2,3,4,seq(4.5,5.5,0.1),6,7,8,9,10) # Compute RMSE values for each lambda using the *test set. rmses &lt;- sapply(lambdas, function(l){ message(&quot;lambda = &quot;, l) # Compute movie, user, genre, and time effects using the test set. # Note that f_t here refers to the variable f_t and not the f_t column in # any of the data.tables. movie_biases_reg &lt;- edx_train[, .(b_i = sum(rating - mu - f_t[weekNum])/(.N+l)), by = &#39;movieId&#39;] temp &lt;- movie_biases_reg[edx_train, on = &#39;movieId&#39;] user_biases_reg &lt;- temp[, .(b_u = sum(rating - mu - b_i - f_t[weekNum])/(.N+l)), by = &#39;userId&#39;] temp &lt;- user_biases_reg[temp, on = &#39;userId&#39;] genre_biases_reg &lt;- temp[, .(b_g = sum(rating - mu - b_i - b_u - f_t[weekNum])/(.N+l)), by = &#39;genres&#39;] # Generate predictions predicted_ratings &lt;- genre_biases_reg[ user_biases_reg[ movie_biases_reg[ edx_test, on = &#39;movieId&#39;], on = &#39;userId&#39;], on = &#39;genres&#39;] |&gt; mutate(pred = mu + b_i + b_u + b_g + f_t[weekNum]) |&gt; pull(pred) # Compute RMSE return(RMSE(predicted_ratings, edx_test$rating)) }) # Plot RMSE against lambda par(cex = 0.7) qplot(lambdas, rmses, xlab = TeX(r&#39;($\\lambda)&#39;), ylab = &#39;RMSE&#39;, geom = c(&#39;point&#39;, &#39;line&#39;)) The optimal value of \\(\\lambda\\) is thus: lambda &lt;- lambdas[which.min(rmses)] lambda ## [1] 4.9 Fitting the regularized model one last time and computing the RMSE on edx_test, we obtain: movie_biases_reg &lt;- edx_train[, .(b_i = sum(rating - mu - f_t[weekNum])/(.N+lambda)), by = &#39;movieId&#39;] temp &lt;- movie_biases_reg[edx_train, on = &#39;movieId&#39;] user_biases_reg &lt;- temp[, .(b_u = sum(rating - mu - b_i - f_t[weekNum])/(.N+lambda)), by = &#39;userId&#39;] temp &lt;- user_biases_reg[temp, on = &#39;userId&#39;] genre_biases_reg &lt;- temp[, .(b_g = sum(rating - mu - b_i - b_u - f_t[weekNum])/(.N+lambda)), by = &#39;genres&#39;] # Generate predictions for the *edx_test* set. predicted_ratings_reg &lt;- genre_biases_reg[ user_biases_reg[ movie_biases_reg[ edx_test, on = &#39;movieId&#39;], on = &#39;userId&#39;], on = &#39;genres&#39;] |&gt; mutate(pred = mu + b_i + b_u + b_g + f_t[weekNum]) |&gt; pull(pred) rm(temp) # Compute RMSE and add to data.table RMSEs &lt;- RMSEs |&gt; add_row(Method = &quot;Movie + user + genre + time effects (regularized)&quot;, RMSE = RMSE(predicted_ratings_reg, edx_test$rating), &quot;RMSE (clamped estimates)&quot; = RMSE(clamp(predicted_ratings_reg), edx_test$rating)) RMSEs[nrow(RMSEs),] |&gt; kable(align=&#39;lrr&#39;, booktabs = T) |&gt; row_spec(0, bold = T) Method RMSE RMSE (clamped estimates) Movie + user + genre + time effects (regularized) 0.8636151 0.8634932 2.8 Section summary The table of RMSEs for all models considered in this section is below. RMSEs |&gt; kable(align=&#39;lrr&#39;, booktabs = T, linesep = &quot;&quot;) |&gt; row_spec(0, bold = T) Method RMSE RMSE (clamped estimates) Mean only 1.0600537 1.0600537 Movie effects 0.9429615 0.9429615 Movie + user effects 0.8646843 0.8644818 Movie + user + genre effects 0.8643241 0.8641138 Movie + user + genre + time effects 0.8641266 0.8639174 Movie + user + genre + time effects (regularized) 0.8636151 0.8634932 The results demonstrate that each added feature has reduced the RMSE, as well as adding regularization and clamping; however, there are diminishing returns as each effect is added to the model. "],["funks-matrix-factorization-algorithm.html", "Chapter 3 Funks matrix factorization algorithm 3.1 Computing the residuals 3.2 The recommenderlab package: first failure 3.3 The rrecsys package: second failure 3.4 Writing our own Funk MF algorithm 3.5 Computing the optimal rank of matrix \\(UV\\) 3.6 Final matrix factorization and RMSE values", " Chapter 3 Funks matrix factorization algorithm In this section, we consider Funks matrix factorization (MF) algorithm (Funk 2006; Koren, Bell, and Volinsky 2009) for rating prediction. We use the model \\(Y \\sim P + UV^\\mathrm{T} + \\varepsilon\\) where: \\(Y\\) is the \\(N_\\mathrm{U}\\times N_\\mathrm{M}\\) rating matrix, i.e., with \\(N_u\\) users and \\(N_i\\) movies, \\(P\\) represents the predictions from best model of the previous section, \\(U\\) and \\(V\\) are \\(N_\\mathrm{U} \\times k\\) and \\(N_\\mathrm{M} \\times k\\) matrices, respectively, where \\(k\\) is the number of latent features to be found. Unknown ratings \\(Y_{u,i}\\) can thus be estimated as \\(P_{u,i} + U_u V_i^\\mathrm{T}\\). The parameter \\(k\\) is also the rank of matrix \\(UV\\); i.e. \\(UV\\) is a rank-\\(k\\) approximation of the residual matrix \\(Y-P\\). Funks MF estimates \\(U\\) and \\(V\\) using gradient descent, but operating only on the known ratings. First, \\(U\\) and \\(V\\) are seeded with random values. Then, for each epoch, the algorithm iterates over all known ratings \\((i,j)\\) in the training set and updates the feature matrices as follows: \\[e_{ij} = Y_{ij} - P_{ij} - U_i V_j^\\mathrm{T}\\] \\[U_i \\gets U_i + \\gamma(e_{ij} V_j - \\lambda U_i)\\] \\[V_j \\gets V_i + \\gamma(e_{ij} U_i - \\lambda V_j)\\] where \\(\\gamma\\) is the learning rate and \\(\\lambda\\) is a regularization parameter. In this report, these are set to 0.02 and 0.001, respectively, in accordance to guidance from Funk (2006). The code for the Funk MF implementation used in this report can be found in Appendix A. 3.1 Computing the residuals The following code computes \\(Y_{u,i} - P_{u,i}\\) for all \\((u,i)\\) in the training set, and creates an index mapping eliminating users and movies with no rating pairs. # Residuals from previous best model previous_train &lt;- genre_biases_reg[ user_biases_reg[ movie_biases_reg[ edx_train, on = &#39;movieId&#39;], on = &#39;userId&#39;], on = &#39;genres&#39;] |&gt; mutate(pred = mu + b_i + b_u + b_g + f_t[weekNum]) |&gt; pull(pred) residuals_train &lt;- as.numeric(edx_train$rating - previous_train) # Test set predictions for previous best model previous_test &lt;- genre_biases_reg[ user_biases_reg[ movie_biases_reg[ edx_test, on = &#39;movieId&#39;], on = &#39;userId&#39;], on = &#39;genres&#39;] |&gt; mutate(pred = mu + b_i + b_u + b_g + f_t[weekNum]) |&gt; pull(pred) # Obtain new movie and user indices **without gaps**, and save the mappings Uidx &lt;- numeric(max(edx_train$userId)) Uidx[unique(edx_train$userId)] = seq(uniqueN(edx_train$userId)) Vidx &lt;- numeric(max(edx_train$movieId)) Vidx[unique(edx_train$movieId)] = seq(uniqueN(edx_train$movieId)) 3.2 The recommenderlab package: first failure The recommenderlab package (Hahsler 2021) contains an funkSVD function that accepts a realRatingMatrix object as input. Note that this object is expected to contain the actual ratings rather than a residual matrix. This object is easy to create and does not consume too much memory: mat &lt;- new( className(&quot;realRatingMatrix&quot;, &quot;recommenderlab&quot;), data = sparseMatrix(Uidx[edx_train$userId], Vidx[edx_train$movieId], x = edx_train$rating) ) object.size(mat) ## 97245808 bytes However, attempting to factor this matrix as follows returns an error. Note that this is just one of several memory allocation requests; there is 32GB of RAM on the laptop used to run this project code. This suggests that recommenderlab uses dense matrices in its internal functions. # NOT RUN # returns: # &lt;simpleError: cannot allocate vector of size 5.6 Gb&gt; tryCatch(recommenderlab::funkSVD(mat), error = print) 3.3 The rrecsys package: second failure Like recommenderlab, the rrecsys package (Çoba 2019) also contains an implementation of the Funk MF algorithm, again accepting the raw ratings as input. However, the following attempt to convert the training set into a format the rrecsys package can understand results in many GB of memory being requested, suggesting that while rrecsys::defineData understands sparse matrix input in coordinate form, the package does not use sparse matrix representations internally: # NOT RUN mat &lt;- rrecsys::defineData(cbind(Uidx[edx_train$userId], Vidx[edx_train$movieId], x = edx_train$rating), sparseMatrix = T, binary = F, minimum = 0.5, maximum = 5, intScale = TRUE) The above operation did not complete after several minutes and was aborted. 3.4 Writing our own Funk MF algorithm In light of the above failures, a fresh implementation of the Funk MF algorithm, using RCpp, was written. The C++ source code is available at https://yinchi.github.io/harvardx-movielens/svd.cpp and is loaded into the R environment below: # Funk matrix factorization. See C++ source for full documentation. # Values for regCoef and learningRate are as suggested by [Funk 2006]. Rcpp::sourceCpp(&quot;svd.cpp&quot;) funk &lt;- function(Uidx, Vidx, residuals, nFeatures, steps = 500, regCoef = 0.02, learningRate = 1e-3) { # Change Uidx and Vidx to 0-based, for C++ only. funkCpp(Uidx[edx_train$userId] - 1, Vidx[edx_train$movieId] - 1, residuals_train, nFeatures, steps, regCoef, learningRate) } 3.5 Computing the optimal rank of matrix \\(UV\\) The following code plots the prediction error of the new model against the number of latent features in the Funk matrix factorization, i.e. the rank of matrix \\(UV\\): # Compute RMSE values for varying number of MF features. set.seed(1) if (!file.exists(&#39;funk_tuning.Rdata&#39;)) { nFeatures &lt;- c(1, 2, 4, 8, seq(12,20), 24, 28, 32) rmses &lt;- sapply(nFeatures, \\(nF){ message(nF, &#39; features&#39;) # Run Funk MF set.seed(1) funkResult &lt;- funk(Uidx, Vidx, residuals_train, nFeatures = nF, steps = 500) U &lt;- funkResult$U V &lt;- funkResult$V # Uidx[u] is the row index of user u in matrix U # Vidx[v] is the row index of movie v in matrix V predicted_ratings_funk &lt;- edx_test |&gt; mutate(pred = previous_test + map2_dbl(userId, movieId, \\(u,v) U[Uidx[u],] %*% V[Vidx[v],])) |&gt; pull(pred) rmse &lt;- RMSE(predicted_ratings_funk, edx_test$rating) message(rmse,&#39;\\n&#39;) return(rmse) }) save(nFeatures,rmses, file = &#39;funk_tuning.Rdata&#39;) } set.seed(1) load(&#39;funk_tuning.Rdata&#39;) par(cex = 0.7) qplot(nFeatures, rmses, xlab = &#39;rank(UV)&#39;, ylab = &#39;RMSE&#39;, geom = c(&#39;point&#39;,&#39;line&#39;)) The optimal number of latent features is: nFeaturesOpt &lt;- nFeatures[which.min(rmses)] nFeaturesOpt ## [1] 14 3.6 Final matrix factorization and RMSE values Using the new model with \\(k=14\\) to predict ratings for the edx_test gives the following RMSE values: # Run Funk MF set.seed(1) if (!file.exists(&#39;funk.Rdata&#39;)) { funkResult &lt;- funk(Uidx, Vidx, residuals_train, nFeatures = nFeaturesOpt, steps = 500) save(nFeaturesOpt, funkResult, file = &#39;funk.Rdata&#39;) } set.seed(1) load(&#39;funk.Rdata&#39;) U &lt;- funkResult$U V &lt;- funkResult$V # Uidx[u] is the row index of user u in matrix U # Vidx[v] is the row index of movie v in matrix V predicted_ratings_funk &lt;- edx_test |&gt; mutate(pred = previous_test + map2_dbl(userId, movieId, \\(u,v) U[Uidx[u],] %*% V[Vidx[v],])) |&gt; pull(pred) rmse &lt;- RMSE(predicted_ratings_funk, edx_test$rating) # Compute RMSE and add to data.table RMSEs &lt;- RMSEs |&gt; add_row(Method = &quot;Section 2 best model + Matrix factorization&quot;, RMSE = RMSE(predicted_ratings_funk, edx_test$rating), &quot;RMSE (clamped estimates)&quot; = RMSE(clamp(predicted_ratings_funk), edx_test$rating)) RMSEs[nrow(RMSEs),] |&gt; kable(align=&#39;lrr&#39;, booktabs = T) |&gt; row_spec(0, bold = T) Method RMSE RMSE (clamped estimates) Section 2 best model + Matrix factorization 0.7949206 0.7939817 The RMSEs of all models in this report, evaluated using edx_test, are as follows: RMSEs |&gt; kable(align=&#39;lrr&#39;, booktabs = T, linesep = &quot;&quot;) |&gt; row_spec(0, bold = T) Method RMSE RMSE (clamped estimates) Mean only 1.0600537 1.0600537 Movie effects 0.9429615 0.9429615 Movie + user effects 0.8646843 0.8644818 Movie + user + genre effects 0.8643241 0.8641138 Movie + user + genre + time effects 0.8641266 0.8639174 Movie + user + genre + time effects (regularized) 0.8636151 0.8634932 Section 2 best model + Matrix factorization 0.7949206 0.7939817 We now submit our best model, i.e. \\[\\begin{equation} Y_{u,i} \\sim \\mu + b_{1;i} + b_{2;u} + b_{3;g(i)} + f(t_{u,i}) + UV^\\mathrm{T} + \\varepsilon_{u,i}, \\tag{3.1} \\end{equation}\\] with parameters mu, movie_biases_reg, user_biases_reg, genre_biases_reg, f_t, U, and V, for final validation. References "],["final-validation.html", "Chapter 4 Final validation", " Chapter 4 Final validation We select our best model (3.1) for validation against the validation dataset. save(mu, movie_biases_reg, user_biases_reg, genre_biases_reg, f_t, Uidx, Vidx, U, V, file = &#39;FINAL_model.Rdata&#39;) The number of parameters in the model is: nrow(movie_biases_reg) + nrow(user_biases_reg) + nrow(genre_biases_reg) + length(f_t) + length(U) + length(V) ## [1] 1209852 The final RMSE computed with the validation set is: predicted_ratings_FINAL_VALIDATION &lt;- validation |&gt; mutate(weekNum = (timestamp - min(timestamp)) |&gt; as.numeric(unit = &quot;days&quot;) |&gt; {\\(x) floor(x/7) + 1}() ) |&gt; mutate(f_t = f_t[weekNum]) |&gt; left_join(movie_biases_reg, by=&#39;movieId&#39;) |&gt; left_join(user_biases_reg, by=&#39;userId&#39;) |&gt; left_join(genre_biases_reg, by=&#39;genres&#39;) |&gt; mutate(pred = mu + b_i + b_u + b_g + f_t + map2_dbl(userId, movieId, \\(u,v) U[Uidx[u],] %*% V[Vidx[v],])) |&gt; pull(pred) |&gt; clamp() # Compute RMSE and add to data.table RMSE(predicted_ratings_FINAL_VALIDATION, validation$rating) ## [1] 0.7941947 The plot below plots a histogram of prediction errors: par(cex = 0.7) hist(predicted_ratings_FINAL_VALIDATION - validation$rating, 50, xlab = &#39;Prediction Error&#39;, main = &#39;&#39;) Below is a plot of the cumulative distribution of the absolute error: the_ecdf &lt;- ecdf(predicted_ratings_FINAL_VALIDATION - validation$rating) par(cex = 0.7) qplot(seq(0,4.5,0.001), the_ecdf(seq(0,4.5,0.001)), xlab = &#39;Absoulute error of prediction&#39;, ylab = &#39;Empirical CDF&#39;, geom = &#39;line&#39;) The proportion of predictions are within half a star of the actual rating is: mean(abs(predicted_ratings_FINAL_VALIDATION - validation$rating) &lt; 0.5) ## [1] 0.5169635 "],["concluding-remarks.html", "Chapter 5 Concluding remarks 5.1 The cmfrec package and benchmarks", " Chapter 5 Concluding remarks In this project, we train a recommender system to predict movie ratings on a scale from 0.5 to 5, using the Movielens 10M (GroupLens 2009) dataset. Our final model considers user, movie, genre, and time-based biases, and uses Funks matrix factorization to approximate the residuals after these effects have been removed from the ratings. The RMSE achieved by our final model, as evaluated using the validation partition, is 0.7941947. Note that the effect of adding genre and time-based biases was small. In particular, the genres of a movie can be uniquely determined from its movieID, and most movies have been rated many times, decreasing the importance of genre information. For the same reason, adding the year of release of each movie as a model feature is also unlikely to significantly improve the results. However, this result is because the validation set for this project was deliberately constructed not to contain any movies not in the training and test sets. In a live environment, adding genre and time-based information will prove useful for predicting ratings of new movies, where a movie bias cannot be computed (using a zero value is the likely best solution). In this case, adding the year of release as an additional model feature likely would improve prediction accuracy. Another possible feature we could have used is the age of a movie at the time it was rated. The tag information included in the original Movielens 10M dataset (but unused in this project) could also be useful for estimating the ratings of new or rarely rated movies. A consideration is the fact that while this project attempts to minimize the error of the raw ratings, a possibly better approach may be binary: would a user like a movie they have not yet watched, if that movie were recommended to them? If we assume a user enjoys a movie if they rate it 3.5 stars or higher, then the confusion matrix as computed on the validation set is: confusionMatrix(as.factor(ifelse(predicted_ratings_FINAL_VALIDATION &gt;= 3.5, &#39;Good&#39;, &#39;Bad&#39;)), as.factor(ifelse(validation$rating &gt;= 3.5, &#39;Good&#39;, &#39;Bad&#39;)), positive = &#39;Good&#39;) ## Confusion Matrix and Statistics ## ## Reference ## Prediction Bad Good ## Bad 301123 140407 ## Good 110332 448137 ## ## Accuracy : 0.7493 ## 95% CI : (0.7484, 0.7501) ## No Information Rate : 0.5885 ## P-Value [Acc &gt; NIR] : &lt; 2.2e-16 ## ## Kappa : 0.4879 ## ## Mcnemar&#39;s Test P-Value : &lt; 2.2e-16 ## ## Sensitivity : 0.7614 ## Specificity : 0.7318 ## Pos Pred Value : 0.8024 ## Neg Pred Value : 0.6820 ## Prevalence : 0.5885 ## Detection Rate : 0.4481 ## Detection Prevalence : 0.5585 ## Balanced Accuracy : 0.7466 ## ## &#39;Positive&#39; Class : Good ## The accuracy of our model is about three-quarters, with approximately equal sensitivity and specificity. Furthermore, note that while the ratings in the Movielens dataset are discrete, the generated predictions are not. If only discrete predictions are allowed, then a series of thresholds may be fitted to our current model for binning (these thresholds do not have to be a half-star apart and can instead be based on the distribution of true and predicted ratings). It remains to be seen how such an approach would affect the accuracy of our model, as while correct binning decreases the error of a prediction, incorrect binning may instead increase the error of a rating. For example, for a prediction of 3.6 that is binned to 3.5, the error decreases from 0.1 to 0 given a true rating of 3.5, but increases from 0.4 to 0.5 given a true rating of 4.0. 5.1 The cmfrec package and benchmarks After completing this project, I discovered another R package called cmfrec (Cortes 2022a) which can handle the size of the Movielens 10M dataset and in fact uses it for benchmarking (Cortes 2022b). The best reported result among the R implementations has a RMSE of 0.782465, somewhat better than that achieved here. There are three possible reasons why cmfrec outperforms our method in this project. First, the cmfrec algorithms update user and movie biases during each iteration, rather than the static method used here. The benchmarks shown in Cortes (2022b) show that such static methods generally perform worse than methods with iterative bias updates. Second, methods in cmfrec use alternating least squares (ALS) by default rather than the gradient descent method used here, which improves numerical stability/convergence. Another benefit of ALS is the possibility of massive parallelization (Koren, Bell, and Volinsky 2009). Finally, no optimization was performed on the learning and regularization parameters \\(\\lambda\\) and \\(\\gamma\\) in this project. References "],["references.html", "References", " References "],["sec-code.html", "A Code listing: svd.cpp", " A Code listing: svd.cpp // [[Rcpp::depends(RcppArmadillo)]] // [[Rcpp::depends(RcppProgress)]] #include &lt;RcppArmadillo.h&gt; #include &lt;progress.hpp&gt; #include &lt;progress_bar.hpp&gt; /** * @brief Simon Funk&#39;s Matrix Factorization. * * Approximate Y as U*V^T where U and V each have @p nFeatures columns. * * @param coo_i User indexes of the rating matrix Y. * @param coo_j Movie indexes of the rating matrix Y. * @param coo_x Ratings in the rating matrix Y. Note Y is a sparse matrix, where * a zero represents no rating given. * @param nFeatures the number of features to use, i.e. the number of columns in U and V. * @steps Number of epochs. Each epoch refines the U and V estimates by iterating * through all known ratings once. * @regCoef Regularization coefficient, prevents overfitting. * @learningRate learning rate of gradient descent. * * @return An @c RCpp::list object containing U and V. * * @see https://sifter.org/~simon/journal/20061211.html * @see https://github.com/ludovikcoba/rrecsys/ */ // [[Rcpp::export]] Rcpp::List funkCpp( Rcpp::NumericVector coo_i, Rcpp::NumericVector coo_j, Rcpp::NumericVector coo_x, int nFeatures, int steps, double regCoef, double learningRate ) { int nUsers = Rcpp::max(coo_i)+1; // number of users int nItems = Rcpp::max(coo_j)+1; // number of movies (items) int nRatings = coo_x.size(); // number of known ratings // Seed U and V with random values arma::mat U(nUsers, nFeatures, arma::fill::randu); arma::mat V(nItems, nFeatures, arma::fill::randu); U *= sqrt(0.5/nFeatures); V *= sqrt(0.5/nFeatures); // Diagnostics logging Rcpp::Rcerr &lt;&lt; &quot;nUsers:&quot; &lt;&lt; nUsers &lt;&lt; &quot;, &quot;; Rcpp::Rcerr &lt;&lt; &quot;nItems:&quot; &lt;&lt; nItems &lt;&lt; &quot;, &quot;; Rcpp::Rcerr &lt;&lt; &quot;nRatings:&quot; &lt;&lt; nRatings &lt;&lt; std::endl; // Progress bar for R console Progress p(steps, true); // Main loop for (int ss = 0; ss &lt; steps; ss++) { // Kill program if user has requested it (Ctrl+C in most consoles) Rcpp::checkUserInterrupt(); // iterate over known ratings for (int r = 0; r &lt; nRatings; r++) { int i = coo_i[r]; // user index int j = coo_j[r]; // item index double err = coo_x[r] - arma::dot(U.row(i), V.row(j)); // prediction error // update features U.row(i) += learningRate * (err*V.row(j) - regCoef*U.row(i)); V.row(j) += learningRate * (err*U.row(i) - regCoef*V.row(j)); } // Report progress p.increment(); } Rcpp::Rcerr &lt;&lt; std::endl; // add gap between progress bars of multiple runs // Return list(U,V) Rcpp::List ret; ret[&quot;U&quot;] = U; ret[&quot;V&quot;] = V; return ret; } "],["session-info.html", "B Session info", " B Session info sessionInfo() ## R version 4.1.3 (2022-03-10) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 22000) ## ## Matrix products: default ## ## Random number generation: ## RNG: Mersenne-Twister ## Normal: Inversion ## Sample: Rounding ## ## locale: ## [1] LC_COLLATE=English_Hong Kong SAR.1252 LC_CTYPE=English_Hong Kong SAR.1252 ## [3] LC_MONETARY=English_Hong Kong SAR.1252 LC_NUMERIC=C ## [5] LC_TIME=English_Hong Kong SAR.1252 ## system code page: 65001 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] recommenderlab_0.2-7 registry_0.5-1 proxy_0.4-26 arules_1.7-3 Matrix_1.4-1 ## [6] lubridate_1.8.0 caret_6.0-91 lattice_0.20-45 forcats_0.5.1 stringr_1.4.0 ## [11] dplyr_1.0.8 purrr_0.3.4 readr_2.1.2 tidyr_1.2.0 tibble_3.1.6 ## [16] ggplot2_3.3.5 tidyverse_1.3.1 patchwork_1.1.1 latex2exp_0.9.4 data.table_1.14.2 ## [21] kableExtra_1.3.4 knitr_1.38 magrittr_2.0.3 conflicted_1.1.0 pacman_0.5.1 ## ## loaded via a namespace (and not attached): ## [1] colorspace_2.0-3 ellipsis_0.3.2 class_7.3-20 RcppArmadillo_0.11.0.0.0 ## [5] fs_1.5.2 rstudioapi_0.13 listenv_0.8.0 farver_2.1.0 ## [9] bit64_4.0.5 prodlim_2019.11.13 fansi_1.0.3 xml2_1.3.3 ## [13] codetools_0.2-18 splines_4.1.3 cachem_1.0.6 jsonlite_1.8.0 ## [17] pROC_1.18.0 broom_0.7.12 dbplyr_2.1.1 compiler_4.1.3 ## [21] httr_1.4.2 backports_1.4.1 assertthat_0.2.1 fastmap_1.1.0 ## [25] cli_3.2.0 htmltools_0.5.2 tools_4.1.3 gtable_0.3.0 ## [29] glue_1.6.2 reshape2_1.4.4 float_0.2-6.1 Rcpp_1.0.8.3 ## [33] raster_3.5-15 cellranger_1.1.0 jquerylib_0.1.4 vctrs_0.4.0 ## [37] svglite_2.1.0 nlme_3.1-157 iterators_1.0.14 timeDate_3043.102 ## [41] xfun_0.30 gower_1.0.0 RcppProgress_0.4.2 globals_0.14.0 ## [45] rvest_1.0.2 irlba_2.3.5 lifecycle_1.0.1 terra_1.5-21 ## [49] future_1.24.0 MASS_7.3-56 scales_1.1.1 ipred_0.9-12 ## [53] vroom_1.5.7 hms_1.1.1 parallel_4.1.3 yaml_2.3.5 ## [57] memoise_2.0.1 sass_0.4.1 rpart_4.1.16 stringi_1.7.6 ## [61] highr_0.9 foreach_1.5.2 e1071_1.7-9 hardhat_0.2.0 ## [65] lava_1.6.10 rlang_1.0.2 pkgconfig_2.0.3 systemfonts_1.0.4 ## [69] evaluate_0.15 labeling_0.4.2 recipes_0.2.0 bit_4.0.4 ## [73] tidyselect_1.1.2 parallelly_1.30.0 plyr_1.8.7 bookdown_0.25 ## [77] R6_2.5.1 generics_0.1.2 recosystem_0.5 DBI_1.1.2 ## [81] pillar_1.7.0 haven_2.4.3 withr_2.5.0 mgcv_1.8-40 ## [85] sp_1.4-6 survival_3.3-1 nnet_7.3-17 future.apply_1.8.1 ## [89] modelr_0.1.8 crayon_1.5.1 utf8_1.2.2 tzdb_0.3.0 ## [93] rmarkdown_2.13 grid_4.1.3 readxl_1.4.0 ModelMetrics_1.2.2.2 ## [97] reprex_2.0.1 digest_0.6.29 webshot_0.5.2 stats4_4.1.3 ## [101] munsell_0.5.0 viridisLite_0.4.0 bslib_0.3.1 tidyverse::tidyverse_conflicts() ## -- Conflicts ----------------------------------------------------------------------------- tidyverse_conflicts() -- ## x lubridate::as.difftime() masks base::as.difftime() ## x dplyr::between() masks data.table::between() ## x lubridate::date() masks base::date() ## x Matrix::expand() masks tidyr::expand() ## x tidyr::extract() masks magrittr::extract() ## x dplyr::filter() masks stats::filter() ## x dplyr::first() masks data.table::first() ## x dplyr::group_rows() masks kableExtra::group_rows() ## x lubridate::hour() masks data.table::hour() ## x arules::intersect() masks lubridate::intersect(), base::intersect() ## x lubridate::isoweek() masks data.table::isoweek() ## x dplyr::lag() masks stats::lag() ## x dplyr::last() masks data.table::last() ## x caret::lift() masks purrr::lift() ## x lubridate::mday() masks data.table::mday() ## x lubridate::minute() masks data.table::minute() ## x lubridate::month() masks data.table::month() ## x Matrix::pack() masks tidyr::pack() ## x lubridate::quarter() masks data.table::quarter() ## x arules::recode() masks dplyr::recode() ## x lubridate::second() masks data.table::second() ## x purrr::set_names() masks magrittr::set_names() ## x arules::setdiff() masks lubridate::setdiff(), base::setdiff() ## x purrr::transpose() masks data.table::transpose() ## x arules::union() masks lubridate::union(), base::union() ## x Matrix::unpack() masks tidyr::unpack() ## x lubridate::wday() masks data.table::wday() ## x lubridate::week() masks data.table::week() ## x lubridate::yday() masks data.table::yday() ## x lubridate::year() masks data.table::year() "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
